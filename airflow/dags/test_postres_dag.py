from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.providers.postgres.hooks.postgres import PostgresHook
from datetime import datetime

def test_postgres_conn_safe():
    print("ğŸš€ PostgreSQL ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹œì‘")

    hook = PostgresHook(postgres_conn_id="conn_postgres")

    # 1ï¸âƒ£ ì»¤ë„¥ì…˜ ìƒì„±
    conn = hook.get_conn()
    print("âœ… DB ì»¤ë„¥ì…˜ ìƒì„± ì„±ê³µ")

    cur = conn.cursor()

    # 2ï¸âƒ£ ìµœì†Œ ì¿¼ë¦¬ (ì‹œìŠ¤í…œ ì •ë³´ë§Œ)
    cur.execute("SELECT 1;")
    print("âœ… SELECT 1 ì‹¤í–‰ ì„±ê³µ")

    # 3ï¸âƒ£ í˜„ì¬ DB / ìœ ì €ë§Œ í™•ì¸ (ë°ì´í„° ì˜í–¥ ì—†ìŒ)
    cur.execute("SELECT current_database(), current_user;")
    db, user = cur.fetchone()
    print(f"ğŸ“Œ connected_db={db}, connected_user={user}")

    cur.close()
    conn.close()

    print("ğŸ‰ PostgreSQL ì—°ê²° í…ŒìŠ¤íŠ¸ ì™„ë£Œ")

with DAG(
    dag_id="test_postgres_connection_safe",
    start_date=datetime(2025, 1, 1),
    schedule_interval=None,
    catchup=False,
    tags=["test", "postgres", "safe"],
) as dag:

    test_postgres = PythonOperator(
        task_id="test_postgres_connection",
        python_callable=test_postgres_conn_safe,
    )
